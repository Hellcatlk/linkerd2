image: prom/prometheus:v2.15.2
args:
  storage.tsdb.path: /data
  storage.tsdb.retention.time: 6h
  config.file: /etc/prometheus/prometheus.yml
  log.level: debug
globalConfig:
  scrape_interval: 10s
  scrape_timeout: 10s
  evaluation_interval: 10s
scrapeConfigs:
- job_name: 'prometheus'
  static_configs:
  - targets: ['localhost:9090']

#  Required for: https://grafana.com/grafana/dashboards/315
- job_name: 'kubernetes-nodes-cadvisor'
  scheme: https
  tls_config:
    ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    insecure_skip_verify: true
  bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

  kubernetes_sd_configs:
  - role: node
  relabel_configs:
  - action: labelmap
    regex: __meta_kubernetes_node_label_(.+)
  - target_label: __address__
    replacement: kubernetes.default.svc:443
  - source_labels: [__meta_kubernetes_node_name]
    regex: (.+)
    target_label: __metrics_path__
    replacement: /api/v1/nodes/$1/proxy/metrics/cadvisor
  metric_relabel_configs:
  - source_labels: [__name__]
    regex: '(container|machine)_(cpu|memory|network|fs)_(.+)'
    action: keep
  - source_labels: [__name__]
    regex: 'container_memory_failures_total' # unneeded large metric
    action: drop

- job_name: 'linkerd-service-mirror'
  kubernetes_sd_configs:
  - role: pod
  relabel_configs:
  - source_labels:
    - __meta_kubernetes_pod_label_linkerd_io_control_plane_component
    - __meta_kubernetes_pod_container_port_name
    action: keep
    regex: linkerd-service-mirror;admin-http$
  - source_labels: [__meta_kubernetes_pod_container_name]
    action: replace
    target_label: component